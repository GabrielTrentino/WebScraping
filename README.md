![Principal](https://github.com/GabrielTrentino/WebScraping/blob/master/00-img/00-WebScraping.png?raw=true)

# **Projetos de Web Scraping:**

*Web Scraping* é uma forma de mineração de dados que permite a extração de informações em sites da internet para serem estruturadas em posterior análise. Essa ferramenta é uma **forma automatizada de se obter dados públicos em sites** através da utilização de algumas bibliotecas como `Scrapy`, `Beautiful Soup` e `Selenium`, por exemplo. 

O *Web Scraping* atualmente é classificada como uma `grey-area` legal nos Estados Unidos, isso é, poucos sabem lidar com a legalidade de sua prática (como elucidada no [video](https://www.youtube.com/watch?v=tcMdWM8wmqs)). Por essa razão, alguns sites evitam o congestionamento do trafego causado por um script de *Web Scraping* utilizando o banimento de IP.

Documentação das Biblitoecas em Python:
* [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
* [Scrapy](https://docs.scrapy.org/en/latest/)
* [Selenium](https://selenium-python.readthedocs.io/)

## **Books to Scrape:**
![Banner](https://github.com/GabrielTrentino/WebScraping/blob/master/00-img/01-BooksToScrapeBanner.png?raw=true)

[Books to Scrape](http://books.toscrape.com/) é um site criado com a **unica finalidade de praticar o *Web Scraping*** e, a partir desse site, o [Meigarom](https://www.youtube.com/channel/UCar5Cr-pVz08GY_6I3RX9bA) a elaboração de um Projeto de Data Engineering em seu [post](https://sejaumdatascientist.com/o-projeto-de-data-engineering-para-o-seu-portfolio/) na qual foi inspiração para realizar este projeto. A Situação Ficticia foi sintetizada com minhas palavras de acordo com a ideia geral passada no post.

Situação Ficticia: Uma Startup de troca de livros possui um modelo de negócio à base na troca de livros cadastrados pelo usuário. O objetivo como Data Scientist é de construir um **Sistema de Recomendação de Compra** de livros melhores avaliados por gênero. Logo, antes de construir um sistema de recomendação, você precisa coletar e armazenar os dados do site. Portanto seu primeiro trabalho como um Data Scientist será coletar e armazenar os seguintes dados:

1. O **nome** do livro;
2. A **categoria** do livro;
3. O **número de estrelas** que o livro recebeu;
4. O **preço** do livro;
5. Se o livro **está em Estoque ou não**.

Os outros processos metodologicos estão disponíveis no [README.md](https://github.com/GabrielTrentino/WebScraping/tree/master/01-BooksToScrape) do projeto. A análise exploratória e as informações para as possíveis tomadas de decisão estão disponíveis no [notebook](https://github.com/GabrielTrentino/WebScraping/blob/master/01-BooksToScrape/Books_To_Scrape.ipynb)

# **Dúvidas e Redes Sociais:**
O repositório aumentará o seu tamanho de acordo com as realizações dos cursos. E claro, aceito recomendações de cursos, livros ou vídeos! Qualquer duvida me chame no [LinkedIn](https://www.linkedin.com/in/gabriel-trentino-froes-415558144/).
